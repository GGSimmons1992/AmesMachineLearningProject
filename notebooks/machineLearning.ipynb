{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8427d88a-7ab9-4e43-b6f2-6fb660b1671f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3357: DtypeWarning: Columns (36,40,81,87) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from os.path import exists\n",
    "from os import remove\n",
    "import sklearn.linear_model as lm\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../util/\")\n",
    "import util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb46c71-7e59-4a5c-b5cb-be0ced36eadb",
   "metadata": {},
   "source": [
    "# Add Dummies and Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b861e7-4ead-4a73-b7fc-ba8088801a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (75) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "housingTrainWithDummiesExists = exists('../data/housingTrainWithDummies.csv')\n",
    "housingTestWithDummiesExists = exists('../data/housingTestWithDummies.csv')\n",
    "housingTrainWithoutDummiesExists = exists('../data/housingTrainWithoutDummies.csv')\n",
    "housingTestWithoutDummiesExists = exists('../data/housingTestWithoutDummies.csv')\n",
    "relatedDummiesDictionaryExists = exists('../data/relatedDummiesDictionary.json')\n",
    "\n",
    "if (housingTrainWithDummiesExists and housingTestWithDummiesExists and\n",
    "   housingTrainWithoutDummiesExists and housingTestWithoutDummiesExists and\n",
    "   relatedDummiesDictionaryExists):\n",
    "    housingTrainWithDummies = pd.read_csv('../data/housingTrainWithDummies.csv')\n",
    "    housingTestWithDummies = pd.read_csv('../data/housingTestWithDummies.csv')\n",
    "    housingTrainWithoutDummies = pd.read_csv('../data/housingTrainWithoutDummies.csv')\n",
    "    housingTestWithoutDummies = pd.read_csv('../data/housingTestWithoutDummies.csv')\n",
    "    with open('../data/relatedDummiesDictionary.json') as d:\n",
    "        relatedDummiesDictionary = json.load(d)\n",
    "    for df in [housingTrainWithDummies,housingTestWithDummies,housingTrainWithoutDummies,housingTestWithoutDummies]:\n",
    "        df[\"MSSubClass\"] = df[\"MSSubClass\"].apply(str)\n",
    "    \n",
    "else:\n",
    "    if (housingTrainWithDummiesExists):\n",
    "        remove('../data/housingTrainWithDummies.csv')\n",
    "    if (housingTestWithDummiesExists):\n",
    "        remove('../data/housingTestWithDummies.csv')\n",
    "    if (housingTrainWithoutDummiesExists):\n",
    "        remove('../data/housingTrainWithoutDummies.csv')\n",
    "    if (housingTestWithoutDummiesExists):\n",
    "        remove('../data/housingTestWithoutDummies.csv')\n",
    "    if (relatedDummiesDictionaryExists):\n",
    "        remove('../data/relatedDummiesDictionary.json')\n",
    "    \n",
    "    amesHousing = pd.read_csv('../data/Ames_Housing_Price_Data.csv')   \n",
    "    \n",
    "    amesHousing['MSSubClass'] = amesHousing['MSSubClass'].apply(str)\n",
    "    \n",
    "    amesHousingCategoricalData = amesHousing.select_dtypes(include=['O'])\n",
    "    for col in amesHousingCategoricalData.columns:\n",
    "        amesHousing[col]=amesHousing[col].fillna('nan')\n",
    "    relatedDummiesDictionary = {}\n",
    "    for col in amesHousingCategoricalData.columns:\n",
    "        dummyData = pd.get_dummies(amesHousing[col],prefix=col,drop_first=True)\n",
    "        for dummyCol in dummyData.columns:\n",
    "            relatedDummiesDictionary[str(dummyCol)] = list(dummyData.columns)\n",
    "        amesHousing = pd.concat([amesHousing,dummyData],axis=1)\n",
    "    with open('../data/relatedDummiesDictionary.json', 'w') as fp:\n",
    "        json.dump(relatedDummiesDictionary, fp)\n",
    "    \n",
    "    salesPrice = amesHousing['SalePrice']\n",
    "    X = amesHousing.drop(['SalePrice'], axis=1)\n",
    "    \n",
    "    housingTrainWithDummies, housingTestWithDummies, salesPriceTrain, salesPriceTest = train_test_split(X, salesPrice, test_size=0.2)\n",
    "    \n",
    "    housingTrainWithDummies['SalePrice'] = salesPriceTrain\n",
    "    housingTestWithDummies['SalePrice'] = salesPriceTest\n",
    "    \n",
    "    dummyColumns = list(relatedDummiesDictionary.keys())\n",
    "    housingTrainWithoutDummies = housingTrainWithDummies.drop(dummyColumns, axis=1)\n",
    "    housingTestWithoutDummies = housingTestWithDummies.drop(dummyColumns, axis=1)\n",
    "    \n",
    "    housingTrainWithDummies.to_csv('../data/housingTrainWithDummies.csv')\n",
    "    housingTestWithDummies.to_csv('../data/housingTestWithDummies.csv')\n",
    "    housingTrainWithoutDummies.to_csv('../data/housingTrainWithoutDummies.csv')\n",
    "    housingTestWithoutDummies.to_csv('../data/housingTestWithoutDummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472d8ad3-35c2-4c7d-b185-5959deef7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((\"ISUDistance\" not in housingTrainWithoutDummies.columns) or \n",
    "    (\"ISUDistance\" not in housingTrainWithDummies.columns)):\n",
    "    housingTrainWithoutDummies = util.returnDFWithISUDistance(housingTrainWithoutDummies,True)\n",
    "    housingTrainWithDummies[\"ISUDistance\"] = housingTrainWithoutDummies[\"ISUDistance\"]\n",
    "    housingTrainWithDummies.to_csv('../data/housingTrainWithDummies.csv')\n",
    "    housingTrainWithoutDummies.to_csv('../data/housingTrainWithoutDummies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c069562-0338-4b38-bbe1-43a21cf9ecf2",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cec6e3-f1c3-4d15-b416-321139409ea7",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b9f5551-1551-463f-b01d-8b60b6b62c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingTrainNumerical = housingTrainWithDummies.select_dtypes(include=['uint8','int64','float64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5335d9f-3819-4484-9e2e-12cd5c758689",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (exists('../data/trainNanReplacementValuesDictionary.json')):\n",
    "    with open('../data/trainNanReplacementValuesDictionary.json') as d:\n",
    "        trainNanReplacementValuesDictionary = json.load(d)\n",
    "else:\n",
    "    trainNanReplacementValuesDictionary = {}\n",
    "    for col in housingTrainNumerical:\n",
    "        if col in [\"YearBuilt\",\"YearRemodAdd\",\"GarageYrBlt\",\"YrSold\",\"ISUDistance\"]:\n",
    "            trainNanReplacementValuesDictionary[str(col)] = housingTrainNumerical[col].mean()\n",
    "        elif col in [\"OverallQual\",\"OverallCond\",\"MoSold\"]:\n",
    "            trainNanReplacementValuesDictionary[str(col)] = round(np.mean(housingTrainNumerical[col].mode().values))\n",
    "        else:\n",
    "            trainNanReplacementValuesDictionary[str(col)] = 0\n",
    "    with open('../data/trainNanReplacementValuesDictionary.json', 'w') as fp:\n",
    "        json.dump(trainNanReplacementValuesDictionary, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13390392-4635-40cc-b19c-00bf2c57c9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../util/util.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(trainNanReplacementValuesDictionary[str(col)])\n"
     ]
    }
   ],
   "source": [
    "housingTrainNumerical = util.replaceNansWithTrainingDataValues(housingTrainNumerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6206d0-9dd7-4d71-a97f-411a5ff9b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "salesPrice = housingTrainNumerical[\"SalePrice\"]\n",
    "X = housingTrainNumerical.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ed49f2-bb34-4b2c-b01b-09686f112c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialAlpha = [1]+list(np.linspace(50,1000,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "480e9609-b98a-4a04-9cde-b4e0d6970f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_para_elsatic_net_initial = {'alpha': initialAlpha, 'l1_ratio': np.linspace(0,1,11)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65843715-217c-431a-9c14-894c2cef3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticNet = ElasticNet()\n",
    "if False:\n",
    "    grid_search_elastic_net = ms.GridSearchCV(elasticNet, grid_para_elsatic_net_initial, scoring='accuracy', cv=5, n_jobs=-1, return_train_score=True)\n",
    "    grid_search_elastic_net.fit(X,salesPrice)\n",
    "    grid_search_elastic_net.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17f1105a-0623-4991-a5a7-8a7e8ede1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalAlpha = [1] + list(np.linspace(5,50,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3ebd21-606a-46ef-a0ae-896029ff5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_para_elsatic_net_final = {'alpha': finalAlpha, 'l1_ratio': [0.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f372d0-bab7-41f2-b562-944151ad0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 797266995580.6594, tolerance: 1180153387.246548\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1, 'l1_ratio': 0.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_elastic_net = ms.GridSearchCV(elasticNet, grid_para_elsatic_net_final, scoring='accuracy', cv=5, n_jobs=-1, return_train_score=True)\n",
    "grid_search_elastic_net.fit(X,salesPrice)\n",
    "grid_search_elastic_net.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e5b833-00e6-4d40-8656-3b75c7d30f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists('../data/sigCorrDictionary.json'):\n",
    "    with open('../data/sigCorrDictionary.json') as d:\n",
    "        sigCorrDictionary = json.load(d)\n",
    "else:\n",
    "    correlationList = []\n",
    "    pairList = []\n",
    "    pValList = []\n",
    "    for i in range(len(X.columns)):\n",
    "        for j in range(len(X.columns)):\n",
    "            if i<j:\n",
    "                iColumn = X.columns[i]\n",
    "                jColumn = X.columns[j]\n",
    "                pairList.append(iColumn+'-'+jColumn)\n",
    "                corrVal,pVal = stats.spearmanr(X[iColumn],\n",
    "                                              X[jColumn])\n",
    "                correlationList.append(corrVal)\n",
    "                pValList.append(pVal)\n",
    "\n",
    "    amesHousingCorreltaion = pd.DataFrame({\"pair\":pairList,\n",
    "                                    \"corr\":correlationList,\n",
    "                                    \"pVal\":pValList\n",
    "                                   },columns=[\"pair\",\"corr\",\"pVal\"]).sort_values(by=[\"pVal\",\"corr\"],\n",
    "                                                                                 ascending=[True,False])\n",
    "\n",
    "    amesHousingSigCorrs = amesHousingCorreltaion[(np.isnan(amesHousingCorreltaion['pVal'])==False) & (amesHousingCorreltaion['pVal'] < 0.05)]\n",
    "    absRValues = abs(amesHousingSigCorrs['corr'])\n",
    "    amesHousingSigCorrs = amesHousingSigCorrs[abs(amesHousingSigCorrs['corr']) > absRValues.quantile(.975)]\n",
    "\n",
    "    sigCorrDictionary = {}\n",
    "    for col in X.columns:\n",
    "        correlatedRelations = (amesHousingSigCorrs[amesHousingSigCorrs['pair'].str.contains(col)])[\"pair\"]\n",
    "        correlatedColumns = [name.replace(\"-\",\"\").replace(col,\"\") for name in correlatedRelations]\n",
    "        relatedDummies = []\n",
    "        for corrCol in correlatedColumns:\n",
    "            if corrCol in relatedDummiesDictionary.keys():\n",
    "                relatedDummies = relatedDummies + relatedDummiesDictionary[corrCol]\n",
    "        correlatedColumns = list(set(correlatedColumns + relatedDummies))\n",
    "        sigCorrDictionary[col] = correlatedColumns\n",
    "    with open('../data/sigCorrDictionary.json', 'w') as fp:\n",
    "        json.dump(sigCorrDictionary, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330ba8c2-2fcf-4a8c-8a7c-6c3b38b4a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseV1 = pd.DataFrame()\n",
    "prebaseV2 = pd.DataFrame()\n",
    "baseV2 = pd.DataFrame()\n",
    "\n",
    "linmodel = lm.LinearRegression()\n",
    "linmodel.fit(np.log(X[['GrLivArea']]),np.log(salesPrice))\n",
    "baseV1[f'GrLivArea^{round(linmodel.coef_[0],2)}'] = X['GrLivArea'] ** round(linmodel.coef_[0],2)\n",
    "\n",
    "linmodel = lm.LinearRegression()\n",
    "XWithNeighborhood = pd.merge(X,housingTrainWithDummies[[\"PID\",\"Neighborhood\"]],how='left', left_on='PID', right_on='PID')\n",
    "Nbr_quantile = XWithNeighborhood.groupby('Neighborhood')['GrLivArea'].quantile(0.8)\n",
    "joint_Nbr_quantile = pd.merge(XWithNeighborhood[['Neighborhood']], Nbr_quantile, how='left', left_on='Neighborhood', right_index=True)\n",
    "smaller_home = XWithNeighborhood.GrLivArea < joint_Nbr_quantile.GrLivArea\n",
    "\n",
    "small = []\n",
    "large = []\n",
    "for i,isSmall in enumerate(smaller_home):\n",
    "    if isSmall:\n",
    "        small.append(XWithNeighborhood.GrLivArea[i])\n",
    "        large.append(0)\n",
    "    else:\n",
    "        small.append(0)\n",
    "        large.append(XWithNeighborhood.GrLivArea[i])\n",
    "linmodel.fit(np.log(XWithNeighborhood[[\"GrLivArea\"]])[smaller_home],np.log(salesPrice)[smaller_home.values])\n",
    "baseV2[f'smallGrLivArea^{round(linmodel.coef_[0],2)}'] = small ** round(linmodel.coef_[0],2)\n",
    "linmodel.fit(np.log(XWithNeighborhood[[\"GrLivArea\"]])[~smaller_home],np.log(salesPrice)[~smaller_home.values])\n",
    "baseV2[f'largeGrLivArea^{round(linmodel.coef_[0],2)}'] = large ** round(linmodel.coef_[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2296d0-0965-4785-ae42-e5623c14d532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2258475231667.5415, tolerance: 933121559.0304306\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2213165450121.7876, tolerance: 933224897.8421112\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2374646029616.0728, tolerance: 966845617.2990716\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2291191782276.207, tolerance: 952532432.1250871\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2207013775942.6465, tolerance: 934474911.4017998\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5325034775137362"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticNet = ElasticNet(alpha=1000,l1_ratio=0.0)\n",
    "results = cross_validate(elasticNet,baseV1,salesPrice)\n",
    "np.mean(results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e7689c6-9992-4b55-9474-ea11ec8b0c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5809009293889638"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticNet = ElasticNet(alpha=1000,l1_ratio=0.5)\n",
    "results = cross_validate(elasticNet,baseV2,salesPrice)\n",
    "np.mean(results['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "323d384c-cbaf-4b70-a757-c3a662c94546",
   "metadata": {},
   "outputs": [],
   "source": [
    "availabilityList = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "551eb167-57e7-40b6-b031-05a708e393fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "availabilityList = util.removeDummiesAndCorrelatedFeaturesFromAvailabilityList(availabilityList,\"GrLivArea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83be3b9c-7bca-4592-ac3c-a6b57453db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garysimmons/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n"
     ]
    }
   ],
   "source": [
    "f_value,p_value = f_regression(X,salesPrice)\n",
    "fValuesSorted = pd.DataFrame({\"colName\":list(X.columns),\n",
    "                             \"f_value\":f_value},\n",
    "                            columns=[\"colName\",\"f_value\"]).sort_values(by=[\"f_value\"],\n",
    "                                                                                 ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82151821-9308-4904-a0a7-35221c493e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0<br>largeGrLivArea^1.24</td>\n",
       "      <td>0.583105</td>\n",
       "      <td>0.580901</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xTrain = baseV2\n",
    "elasticNet = ElasticNet(alpha=1000,l1_ratio=0.5)\n",
    "results = cross_validate(elasticNet,xTrain,salesPrice,return_train_score=True)\n",
    "trainScore = np.mean(results['train_score'])\n",
    "testScore = np.mean(results['test_score'])\n",
    "bestScore = testScore\n",
    "modelEvolution = pd.DataFrame({\"features\":[\"\\n\".join(list(xTrain.columns))],\n",
    "                              \"train_score\":[trainScore],\n",
    "                              \"test_score\":[testScore],\n",
    "                              \"test_score_lift\":[0.0]},\n",
    "                             columns = [\"features\",\"train_score\",\"test_score\",\"test_score_lift\"])\n",
    "util.pretty_print(modelEvolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d40f0442-0931-43d4-8954-844d094e5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r ../images/normalCheck\n",
    "!rm -r ../images/isHeteroskedastic\n",
    "!rm -r ../images/isHomoSkedastic\n",
    "!rm -r ../images/notCentered\n",
    "\n",
    "!mkdir ../images/normalCheck\n",
    "!mkdir ../images/isHeteroskedastic\n",
    "!mkdir ../images/isHomoSkedastic\n",
    "!mkdir ../images/notCentered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73d70f91-94a2-42c9-86d0-76e64590d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diverseNumbers = [col for col in fValuesSorted.colName if (col not in relatedDummiesDictionary.keys() and len(list(set(X[col].values))) > 15)]\n",
    "nonDiverseNumbers = [col for col in fValuesSorted.colName if (col not in relatedDummiesDictionary.keys() and len(list(set(X[col].values))) <= 15)]\n",
    "dummyColumns = [col for col in fValuesSorted.colName if col in relatedDummiesDictionary.keys()]\n",
    "prioritizedList = diverseNumbers + nonDiverseNumbers + dummyColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a75cdc3-c125-4ed6-bc69-db81fd0dee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../util/util.py:155: RuntimeWarning: divide by zero encountered in power\n",
      "  xPow = newX ** power\n",
      "../util/util.py:155: RuntimeWarning: divide by zero encountered in power\n",
      "  xPow = newX ** power\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% complete!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0<br>largeGrLivArea^1.24<br>BsmtUnfSF<br>ScreenPorch<br>EnclosedPorch<br>ISUDistance<br>LowQualFinSF<br>BsmtFinSF2<br>BsmtFullBath<br>OverallCond<br>KitchenAbvGr_invbc_l-0.03_m-0.16_b10.25<br>BsmtHalfBath^0.19<br>PoolArea_invbc_l-0.03_m0.0_b10.09<br>MoSold_invbc_l-0.03_m0.0_b10.07<br>YrSold<br>ExterQual_Fa<br>ExterQual_Gd<br>ExterQual_TA<br>Neighborhood_Blueste<br>Neighborhood_BrDale<br>Neighborhood_BrkSide<br>Neighborhood_ClearCr<br>Neighborhood_CollgCr<br>Neighborhood_Crawfor<br>Neighborhood_Edwards<br>Neighborhood_Gilbert<br>Neighborhood_Greens<br>Neighborhood_GrnHill<br>Neighborhood_IDOTRR<br>Neighborhood_Landmrk<br>Neighborhood_MeadowV<br>Neighborhood_Mitchel<br>Neighborhood_NAmes<br>Neighborhood_NPkVill<br>Neighborhood_NWAmes<br>Neighborhood_NoRidge<br>Neighborhood_NridgHt<br>Neighborhood_OldTown<br>Neighborhood_SWISU<br>Neighborhood_Sawyer<br>Neighborhood_SawyerW<br>Neighborhood_Somerst<br>Neighborhood_StoneBr<br>Neighborhood_Timber<br>Neighborhood_Veenker<br>MasVnrType_BrkFace<br>MasVnrType_None<br>MasVnrType_Stone<br>MasVnrType_nan<br>BsmtExposure_Gd<br>BsmtExposure_Mn<br>BsmtExposure_No<br>BsmtExposure_nan<br>GarageType_Attchd<br>GarageType_Basment<br>GarageType_BuiltIn<br>GarageType_CarPort<br>GarageType_Detchd<br>GarageType_nan<br>HeatingQC_Fa<br>HeatingQC_Gd<br>HeatingQC_Po<br>HeatingQC_TA<br>LotShape_IR2<br>LotShape_IR3<br>LotShape_Reg<br>MSZoning_C (all)<br>MSZoning_FV<br>MSZoning_I (all)<br>MSZoning_RH<br>MSZoning_RL<br>MSZoning_RM<br>PavedDrive_P<br>PavedDrive_Y<br>GarageCond_Fa<br>GarageCond_Gd<br>GarageCond_Po<br>GarageCond_TA<br>GarageCond_nan<br>RoofStyle_Gable<br>RoofStyle_Gambrel<br>RoofStyle_Hip<br>RoofStyle_Mansard<br>RoofStyle_Shed<br>CentralAir_Y<br>SaleType_CWD<br>SaleType_Con<br>SaleType_ConLD<br>SaleType_ConLI<br>SaleType_ConLw<br>SaleType_New<br>SaleType_Oth<br>SaleType_VWD<br>SaleType_WD <br>Electrical_FuseF<br>Electrical_FuseP<br>Electrical_SBrkr<br>Electrical_nan<br>Fence_GdWo<br>Fence_MnPrv<br>Fence_MnWw<br>Fence_nan<br>LandContour_HLS<br>LandContour_Low<br>LandContour_Lvl<br>BsmtCond_Fa<br>BsmtCond_Gd<br>BsmtCond_Po<br>BsmtCond_TA<br>BsmtCond_nan<br>LotConfig_CulDSac<br>LotConfig_FR2<br>LotConfig_FR3<br>LotConfig_Inside<br>ExterCond_Fa<br>ExterCond_Gd<br>ExterCond_Po<br>ExterCond_TA<br>Condition1_Feedr<br>Condition1_Norm<br>Condition1_PosA<br>Condition1_PosN<br>Condition1_RRAe<br>Condition1_RRAn<br>Condition1_RRNe<br>Condition1_RRNn<br>Functional_Maj2<br>Functional_Min1<br>Functional_Min2<br>Functional_Mod<br>Functional_Sal<br>Functional_Typ<br>Alley_Pave<br>Alley_nan<br>MiscFeature_Othr<br>MiscFeature_Shed<br>MiscFeature_TenC<br>MiscFeature_nan</td>\n",
       "      <td>0.638119</td>\n",
       "      <td>0.630646</td>\n",
       "      <td>1.568221e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,col in enumerate(prioritizedList):\n",
    "    if col in availabilityList:\n",
    "        if col in relatedDummiesDictionary.keys():\n",
    "            #print(f'{i*100.0/len(fValuesSorted.colName)}% complete. Sorting {col}')\n",
    "            newX = pd.concat([xTrain,X[relatedDummiesDictionary[col]]],axis=1)\n",
    "        else:\n",
    "            #print(f'{i*100.0/len(fValuesSorted.colName)}% complete. Computing {col}')\n",
    "            valueSet = list(set(X[col].values))\n",
    "            if (len(valueSet) <= 15):\n",
    "                newX = util.engineerSmallFeature(xTrain,X[col],salesPrice,str(col))\n",
    "            elif util.IsHomoskedastic(X[col],salesPrice,str(col)):\n",
    "                newX = xTrain.copy()\n",
    "                newX[col] = X[col]\n",
    "            else:\n",
    "                newX = util.engineerFeature(xTrain,X[col],salesPrice,str(col))\n",
    "        if (type(newX) != type(None)):\n",
    "            elasticNet = ElasticNet(alpha=1000,l1_ratio=0.5)\n",
    "            results = cross_validate(elasticNet,newX,salesPrice,return_train_score=True)\n",
    "            trainScore = np.mean(results['train_score'])\n",
    "            testScore = np.mean(results['test_score'])\n",
    "            if testScore > bestScore:\n",
    "                scoreLift = testScore - bestScore\n",
    "                bestScore = testScore\n",
    "                xTrain = newX\n",
    "                newModel = pd.DataFrame({\"features\":[\"\\n\".join(list(xTrain.columns))],\n",
    "                              \"train_score\":[trainScore],\n",
    "                              \"test_score\":[testScore],\n",
    "                              \"test_score_lift\":[scoreLift]},\n",
    "                             columns = [\"features\",\"train_score\",\"test_score\",\"test_score_lift\"])\n",
    "                modelEvolution = pd.concat([modelEvolution,newModel],axis=0)\n",
    "                availabilityList = util.removeDummiesAndCorrelatedFeaturesFromAvailabilityList(availabilityList,col)\n",
    "print('100% complete!')\n",
    "modelEvolution.reset_index()\n",
    "util.pretty_print(newModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94187d19-d3d6-4b9a-90c3-3cf7f717f8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_score_lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24</td>\n",
       "      <td>0.583105</td>\n",
       "      <td>0.580901</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.584311</td>\n",
       "      <td>0.581405</td>\n",
       "      <td>5.037254e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.586130</td>\n",
       "      <td>0.582765</td>\n",
       "      <td>1.360132e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.601704</td>\n",
       "      <td>0.596666</td>\n",
       "      <td>1.390130e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.601705</td>\n",
       "      <td>0.596667</td>\n",
       "      <td>7.921900e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.609615</td>\n",
       "      <td>0.603503</td>\n",
       "      <td>6.835953e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.610525</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>4.973558e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.610571</td>\n",
       "      <td>0.604046</td>\n",
       "      <td>4.613115e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.610572</td>\n",
       "      <td>0.604047</td>\n",
       "      <td>4.840611e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.637872</td>\n",
       "      <td>0.630399</td>\n",
       "      <td>2.635245e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.637930</td>\n",
       "      <td>0.630457</td>\n",
       "      <td>5.800748e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.637944</td>\n",
       "      <td>0.630471</td>\n",
       "      <td>1.375176e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.637965</td>\n",
       "      <td>0.630492</td>\n",
       "      <td>2.141372e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638011</td>\n",
       "      <td>0.630538</td>\n",
       "      <td>4.595542e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638044</td>\n",
       "      <td>0.630572</td>\n",
       "      <td>3.350827e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638052</td>\n",
       "      <td>0.630580</td>\n",
       "      <td>7.987231e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638062</td>\n",
       "      <td>0.630590</td>\n",
       "      <td>1.056918e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638075</td>\n",
       "      <td>0.630603</td>\n",
       "      <td>1.257566e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638078</td>\n",
       "      <td>0.630606</td>\n",
       "      <td>3.148276e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638080</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>2.529361e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638098</td>\n",
       "      <td>0.630626</td>\n",
       "      <td>1.732770e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638099</td>\n",
       "      <td>0.630627</td>\n",
       "      <td>1.203059e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638102</td>\n",
       "      <td>0.630630</td>\n",
       "      <td>2.486489e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638104</td>\n",
       "      <td>0.630632</td>\n",
       "      <td>2.136523e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638107</td>\n",
       "      <td>0.630635</td>\n",
       "      <td>2.722369e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638108</td>\n",
       "      <td>0.630635</td>\n",
       "      <td>6.840488e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638109</td>\n",
       "      <td>0.630637</td>\n",
       "      <td>1.363748e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638111</td>\n",
       "      <td>0.630638</td>\n",
       "      <td>1.327377e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638112</td>\n",
       "      <td>0.630639</td>\n",
       "      <td>8.813071e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638114</td>\n",
       "      <td>0.630641</td>\n",
       "      <td>1.914096e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638118</td>\n",
       "      <td>0.630645</td>\n",
       "      <td>3.989897e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638119</td>\n",
       "      <td>0.630646</td>\n",
       "      <td>8.505311e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...</td>\n",
       "      <td>0.638119</td>\n",
       "      <td>0.630646</td>\n",
       "      <td>1.568221e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  train_score  test_score  \\\n",
       "0            smallGrLivArea^1.0\\nlargeGrLivArea^1.24     0.583105    0.580901   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.584311    0.581405   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.586130    0.582765   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.601704    0.596666   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.601705    0.596667   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.609615    0.603503   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.610525    0.604000   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.610571    0.604046   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.610572    0.604047   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.637872    0.630399   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.637930    0.630457   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.637944    0.630471   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.637965    0.630492   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638011    0.630538   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638044    0.630572   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638052    0.630580   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638062    0.630590   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638075    0.630603   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638078    0.630606   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638080    0.630609   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638098    0.630626   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638099    0.630627   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638102    0.630630   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638104    0.630632   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638107    0.630635   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638108    0.630635   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638109    0.630637   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638111    0.630638   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638112    0.630639   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638114    0.630641   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638118    0.630645   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638119    0.630646   \n",
       "0  smallGrLivArea^1.0\\nlargeGrLivArea^1.24\\nBsmtU...     0.638119    0.630646   \n",
       "\n",
       "   test_score_lift  \n",
       "0     0.000000e+00  \n",
       "0     5.037254e-04  \n",
       "0     1.360132e-03  \n",
       "0     1.390130e-02  \n",
       "0     7.921900e-07  \n",
       "0     6.835953e-03  \n",
       "0     4.973558e-04  \n",
       "0     4.613115e-05  \n",
       "0     4.840611e-07  \n",
       "0     2.635245e-02  \n",
       "0     5.800748e-05  \n",
       "0     1.375176e-05  \n",
       "0     2.141372e-05  \n",
       "0     4.595542e-05  \n",
       "0     3.350827e-05  \n",
       "0     7.987231e-06  \n",
       "0     1.056918e-05  \n",
       "0     1.257566e-05  \n",
       "0     3.148276e-06  \n",
       "0     2.529361e-06  \n",
       "0     1.732770e-05  \n",
       "0     1.203059e-06  \n",
       "0     2.486489e-06  \n",
       "0     2.136523e-06  \n",
       "0     2.722369e-06  \n",
       "0     6.840488e-07  \n",
       "0     1.363748e-06  \n",
       "0     1.327377e-06  \n",
       "0     8.813071e-07  \n",
       "0     1.914096e-06  \n",
       "0     3.989897e-06  \n",
       "0     8.505311e-07  \n",
       "0     1.568221e-09  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelEvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94eef889-77c6-43cd-b134-e350054e1efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                features     fitValues\n",
      "0              intercept  7.123694e+16\n",
      "1     smallGrLivArea^1.0  7.702459e+01\n",
      "2    largeGrLivArea^1.24  1.231206e+01\n",
      "3              BsmtUnfSF  1.025921e+00\n",
      "4            ScreenPorch  4.471064e+01\n",
      "..                   ...           ...\n",
      "134            Alley_nan  6.585322e+03\n",
      "135     MiscFeature_Othr  7.810626e+03\n",
      "136     MiscFeature_Shed -7.910611e+03\n",
      "137     MiscFeature_TenC  0.000000e+00\n",
      "138      MiscFeature_nan -2.673034e+03\n",
      "\n",
      "[139 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method RegressorMixin.score of LinearRegression()>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linmodel = lm.LinearRegression()\n",
    "linmodel.fit(xTrain,salesPrice)\n",
    "fitValues = [linmodel.intercept_] + list(linmodel.coef_)\n",
    "features = [\"intercept\"] + list(xTrain.columns)\n",
    "modelDescription = pd.DataFrame({\"features\":features,\n",
    "                                \"fitValues\":fitValues}\n",
    "                                ,columns=[\"features\",\"fitValues\"])\n",
    "print(modelDescription)\n",
    "linmodel.score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1298b-3d33-465b-a337-9a3495cb5352",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0456c23-ab12-4759-840d-fafc92cb57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../util/util.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(trainNanReplacementValuesDictionary[str(col)])\n"
     ]
    }
   ],
   "source": [
    "housingTrainNumerical = housingTrainWithDummies.select_dtypes(include=['uint8','int64','float64'])\n",
    "housingTrainNumerical = util.replaceNansWithTrainingDataValues(housingTrainNumerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc2448c7-1e70-409a-a606-ab7e895c1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "treeSalesPrice = housingTrainNumerical[\"SalePrice\"]\n",
    "treeXTrain = housingTrainNumerical.drop([\"SalePrice\"],axis=1)\n",
    "regr = RandomForestRegressor()\n",
    "params = {'n_estimators': 1000, 'max_depth': 20, 'max_features': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba20d3e1-d316-4356-8430-c8fc2451717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    params[\"n_estimators\"]\n",
    "except BaseException:\n",
    "    bestScore = 0.0\n",
    "    nValues = [100,500,1000]\n",
    "    for n in nValues:\n",
    "        regr = RandomForestRegressor(n_estimators = n)\n",
    "        results = cross_validate(regr,treeXTrain,treeSalesPrice)\n",
    "        if np.mean(results[\"test_score\"]) > bestScore:\n",
    "            bestScore = np.mean(results[\"test_score\"])\n",
    "            params[\"n_estimators\"] = n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e910ac52-145f-4176-b713-a402ff5cf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    params[\"max_depth\"]\n",
    "except BaseException:\n",
    "    bestScore = 0.0\n",
    "    depthValues = [10,20,None]\n",
    "    for depth in depthValues:\n",
    "        regr = RandomForestRegressor(n_estimators = params[\"n_estimators\"],\n",
    "                                    max_depth = depth)\n",
    "        results = cross_validate(regr,treeXTrain,treeSalesPrice)\n",
    "        if np.mean(results[\"test_score\"]) > bestScore:\n",
    "            bestScore = np.mean(results[\"test_score\"])\n",
    "            params[\"max_depth\"] = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e53f88a-2b5b-4a87-9296-505922b806fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    params[\"max_features\"]\n",
    "except BaseException:\n",
    "    bestScore = 0.0\n",
    "    nFeatureValues = ['sqrt','log2',None]\n",
    "    for nFeatures in nFeatureValues:\n",
    "        regr = RandomForestRegressor(n_estimators = params[\"n_estimators\"],\n",
    "                                    max_depth = params[\"max_depth\"],\n",
    "                                    max_features = nFeatures)\n",
    "        results = cross_validate(regr,treeXTrain,treeSalesPrice)\n",
    "        if np.mean(results[\"test_score\"]) > bestScore:\n",
    "            bestScore = np.mean(results[\"test_score\"])\n",
    "            params[\"max_features\"] = nFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83f4299d-b85d-48b2-9a21-f5eb5b19af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'max_depth': 20, 'max_features': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9870029564189815"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(params)\n",
    "regr = RandomForestRegressor(n_estimators=params[\"n_estimators\"],\n",
    "                            max_depth = params[\"max_depth\"],\n",
    "                            max_features = params[\"max_features\"])\n",
    "regr.fit(treeXTrain,treeSalesPrice)\n",
    "regr.score(treeXTrain,treeSalesPrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d275089-efe9-4501-9062-3530b59231a6",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2db0677c-faf0-4a17-aa25-7ecf0a56b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((\"ISUDistance\" not in housingTestWithoutDummies.columns) or \n",
    "    (\"ISUDistance\" not in housingTestWithDummies.columns)):\n",
    "    housingTestWithoutDummies = util.returnDFWithISUDistance(housingTestWithoutDummies,True)\n",
    "    housingTestWithDummies[\"ISUDistance\"] = housingTestWithoutDummies[\"ISUDistance\"]\n",
    "    housingTestWithDummies.to_csv('../data/housingTestWithDummies.csv')\n",
    "    housingTestWithoutDummies.to_csv('../data/housingTestWithoutDummies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a832baa5-30d7-4f37-b45a-c480906d6643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../util/util.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(trainNanReplacementValuesDictionary[str(col)])\n"
     ]
    }
   ],
   "source": [
    "housingTestNumerical = housingTestWithDummies.select_dtypes(include=['uint8','int64','float64'])\n",
    "housingTestNumerical = util.replaceNansWithTrainingDataValues(housingTestNumerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd1e1f4-91f0-413b-821f-6fbc83bdb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingTestLinear = housingTestNumerical.copy()\n",
    "housingTestForest = housingTestNumerical.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf82ad-5bae-4e4f-909f-2b5429b6abff",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6759241f-edfd-4d5d-8579-850f3b2b3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "housingTestLinear = pd.merge(housingTestLinear,housingTestWithDummies[[\"PID\",\"Neighborhood\"]],how='left', left_on='PID', right_on='PID')\n",
    "joint_Nbr_quantile = pd.merge(housingTestLinear[['Neighborhood']], Nbr_quantile, how='left', left_on='Neighborhood', right_index=True)\n",
    "smaller_home = housingTestLinear.GrLivArea < joint_Nbr_quantile.GrLivArea\n",
    "\n",
    "small = []\n",
    "large = []\n",
    "for i,isSmall in enumerate(smaller_home):\n",
    "    if isSmall:\n",
    "        small.append(housingTestLinear.GrLivArea[i])\n",
    "        large.append(0)\n",
    "    else:\n",
    "        small.append(0)\n",
    "        large.append(housingTestLinear.GrLivArea[i])\n",
    "\n",
    "housingTestLinear[\"smallGrLivArea^1.0\"] = np.array(small) ** 1.0\n",
    "\n",
    "housingTestLinear[\"largeGrLivArea^1.24\"] = np.array(large) ** 1.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2003c1da-ad60-4f1d-a7bb-6cee2d430c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-8e72c4e040c9>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xTest[col] = housingTestLinear[col]\n",
      "<ipython-input-37-8e72c4e040c9>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xTest[col] = util.InvBoxCox(housingTestLinear['KitchenAbvGr'],\n",
      "<ipython-input-37-8e72c4e040c9>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xTest[col] = housingTestLinear['BsmtHalfBath'] ** 0.19\n",
      "<ipython-input-37-8e72c4e040c9>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xTest[col] = util.InvBoxCox(housingTestLinear['PoolArea'],\n",
      "<ipython-input-37-8e72c4e040c9>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xTest[col] = util.InvBoxCox(housingTestLinear['MoSold'],\n"
     ]
    }
   ],
   "source": [
    "xTest = housingTestLinear[[\"smallGrLivArea^1.0\",\"largeGrLivArea^1.24\"]]\n",
    "xTrainColumns = xTrain.columns\n",
    "for col in xTrainColumns:\n",
    "    if (col in housingTestLinear.columns):\n",
    "        xTest[col] = housingTestLinear[col]\n",
    "    elif str(col) == 'KitchenAbvGr_invbc_l-0.03_m-0.16_b10.25':\n",
    "        xTest[col] = util.InvBoxCox(housingTestLinear['KitchenAbvGr'],\n",
    "                                   -0.03,-0.16,10.25)\n",
    "    elif str(col) == 'BsmtHalfBath^0.19':\n",
    "        xTest[col] = housingTestLinear['BsmtHalfBath'] ** 0.19\n",
    "    elif str(col) == 'PoolArea_invbc_l-0.03_m0.0_b10.09':\n",
    "        xTest[col] = util.InvBoxCox(housingTestLinear['PoolArea'],\n",
    "                                   -0.03,0.0,10.09)\n",
    "    elif str(col) == 'MoSold_invbc_l-0.03_m0.0_b10.07':\n",
    "        xTest[col] = util.InvBoxCox(housingTestLinear['MoSold'],\n",
    "                                   -0.03,0.0,10.07) \n",
    "    else:\n",
    "        print(f'{col} not in housingTestLinear')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c179f087-050b-4fe6-8794-39664182ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.8937699632400333\n",
      "testing score is 0.7792528290132216\n"
     ]
    }
   ],
   "source": [
    "linearTestSalesPrice = housingTestLinear['SalePrice']\n",
    "\n",
    "linmodel = lm.LinearRegression()\n",
    "linmodel.fit(xTrain,salesPrice)\n",
    "print(f'training score is {linmodel.score(xTrain,salesPrice)}')\n",
    "print(f'testing score is {linmodel.score(xTest,linearTestSalesPrice)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c93cd-bf75-40ac-b155-468334811ba4",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6833900f-c992-42bd-aa2a-6d0e4b976b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score = 0.9872878468895974\n",
      "testing score = 0.8153731701778244\n"
     ]
    }
   ],
   "source": [
    "yTestForest = housingTestForest[\"SalePrice\"]\n",
    "XTestForest = housingTestForest.drop([\"SalePrice\"],axis=1)\n",
    "\n",
    "regr = RandomForestRegressor()\n",
    "params = {'n_estimators': 1000, 'max_depth': 20, 'max_features': None}\n",
    "regr = RandomForestRegressor(n_estimators=params[\"n_estimators\"],\n",
    "                            max_depth = params[\"max_depth\"],\n",
    "                            max_features = params[\"max_features\"])\n",
    "regr.fit(treeXTrain,treeSalesPrice)\n",
    "print(f'training score = {regr.score(treeXTrain,treeSalesPrice)}')\n",
    "print(f'testing score = {regr.score(XTestForest,yTestForest)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
